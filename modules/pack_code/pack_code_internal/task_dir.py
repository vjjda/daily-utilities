# Path: modules/pack_code/pack_code_internal/task_dir.py
"""
(Internal Task)
Handles the logic for processing a user-specified directory.
"""

import logging
import argparse
from pathlib import Path
from typing import Dict, Any, List, Optional, Set, Tuple

# Import internal workers
from . import (
    load_config_files,
    resolve_filters,
    scan_files,
    load_files_content
)

__all__ = ["process_pcode_task_dir"]

FileResult = Dict[str, Any] # Type alias

def process_pcode_task_dir(
    scan_dir: Path,
    cli_args: Dict[str, Any],
    logger: logging.Logger,
    processed_files: Set[Path],
    reporting_root: Optional[Path],
    script_file_path: Path
) -> List[FileResult]:
    """
    X·ª≠ l√Ω logic pack_code cho m·ªôt th∆∞ m·ª•c ƒë·∫ßu v√†o.
    """
    logger.info(f"--- üìÅ Qu√©t th∆∞ m·ª•c: {scan_dir.name} ---")
    
    # 1. T·∫£i/Merge Config (c·ª•c b·ªô)
    file_config = load_config_files(scan_dir, logger)
    
    ext_filter_set, ignore_spec, submodule_paths, clean_extensions_set = resolve_filters(
        logger, cli_args, file_config, scan_dir
    )

    # 2. In b√°o c√°o c·∫•u h√¨nh
    logger.info(f"  [C·∫•u h√¨nh √°p d·ª•ng]")
    logger.info(f"    - Extensions: {sorted(list(ext_filter_set))}")
    logger.info(f"    - Ignore (t·ª´ config/CLI+Git): {len(ignore_spec.patterns if ignore_spec else [])} quy t·∫Øc")
    # (Ch√∫ng ta c√≥ th·ªÉ l√†m b√°o c√°o r√µ r√†ng h∆°n n·∫øu c·∫ßn, nh∆∞ng t·∫°m th·ªùi gi·ªØ g·ªçn)
    
    # 3. Qu√©t file
    files_to_pack = scan_files(
         logger=logger,
         start_path=scan_dir, 
         ignore_list=None, # ƒê√£ n·∫±m trong ignore_spec
         ext_filter_set=ext_filter_set,
         submodule_paths=submodule_paths,
         scan_root=scan_dir, 
         script_file_path=script_file_path
    )

    if not files_to_pack:
        logger.info(f"  -> ü§∑ Kh√¥ng t√¨m th·∫•y file n√†o kh·ªõp ti√™u ch√≠ trong: {scan_dir.name}")
        logger.info(f"--- ‚úÖ K·∫øt th√∫c {scan_dir.name} ---")
        logger.info("")
        return []

    logger.info(f"  -> ‚ö° T√¨m th·∫•y {len(files_to_pack)} file, ƒëang ph√¢n t√≠ch...")

    # 4. L·ªçc ra c√°c file ƒë√£ x·ª≠ l√Ω (n·∫øu file l·∫ª ƒë∆∞·ª£c cung c·∫•p)
    unique_files_to_pack = []
    for f in files_to_pack:
        if f.resolve() not in processed_files:
            unique_files_to_pack.append(f)
        
    if not unique_files_to_pack:
        logger.info(f"  -> ‚úÖ T·∫•t c·∫£ file trong th∆∞ m·ª•c n√†y ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (do l√† file input ri√™ng l·∫ª).")
        logger.info(f"--- ‚úÖ K·∫øt th√∫c {scan_dir.name} ---")
        logger.info("")
        return []

    # 5. ƒê·ªçc & L√†m s·∫°ch
    files_content = load_files_content(
        logger=logger,
        file_paths=unique_files_to_pack,
        base_dir=scan_dir,
        all_clean=cli_args.get("all_clean", False),
        clean_extensions_set=clean_extensions_set
    )
    
    final_results: List[FileResult] = []
    
    # 6. T√≠nh to√°n Path v√† t·∫°o Result Object
    for f_path in unique_files_to_pack:
        if f_path in files_content:
            f_content = files_content[f_path]
            
            rel_path: str
            if reporting_root:
                try:
                    rel_path = f_path.relative_to(reporting_root).as_posix()
                except ValueError:
                    rel_path = f_path.as_posix()
            else:
                rel_path = f_path.as_posix()

            final_results.append({
                "path": f_path,
                "content": f_content,
                "rel_path": rel_path
            })
            processed_files.add(f_path.resolve()) # ƒê√°nh d·∫•u ƒë√£ x·ª≠ l√Ω

    logger.info(f"--- ‚úÖ K·∫øt th√∫c {scan_dir.name} ---")
    logger.info("")
    
    return final_results